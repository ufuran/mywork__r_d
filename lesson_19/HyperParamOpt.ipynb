{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-Parameter Optimisation\n",
    "\n",
    "In this notebook we will build a simple pipeline to optimize the hyper-parameters of our architecture as well as of out training setup. For this purpose, we will use the hyper-parameter optimisation framework [Optuna](https://optuna.org/).\n",
    "\n",
    "We will demonstrate how Optuna can help us to select the adequate hyper-parameters to aid our training process. We will use a subset of the classic MNIST dataset to demonstrate how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation\n",
    "\n",
    "Load the dataset, normalize it and extract a subset of it for both training and validation. We extract the subsets only for the sake of demonstration, so the training loops don't take too much time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN_EXAMPLES = 600\n",
    "N_VALID_EXAMPLES = 100\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "EPOCHS = 10\n",
    "\n",
    "# Load MNIST datase\n",
    "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n",
    "num_samples, rows, cols = x_train.shape\n",
    "\n",
    "# Create training subset\n",
    "x_train = x_train[:N_TRAIN_EXAMPLES, ..., np.newaxis]/255\n",
    "y_train = y_train[:N_TRAIN_EXAMPLES]\n",
    "\n",
    "# Create validation subset\n",
    "x_valid = x_valid[:N_VALID_EXAMPLES, ..., np.newaxis]/255\n",
    "y_valid = y_valid[:N_VALID_EXAMPLES]\n",
    "\n",
    "INPUT_SHAPE = (rows, cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnt, idx in enumerate(np.random.randint(0, len(x_train), 24)):\n",
    "    plt.subplot(3, 8, cnt+1), plt.imshow(x_train[idx, ...], cmap='gray')\n",
    "    plt.axis(False), plt.title('Label: ' + str(y_train[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna Pipeline\n",
    "\n",
    "In order to run a hyper-parameter search, we need to define an objective function. This function is a higher level abstraction of the actual loss function we use for tune the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Objective function that controls the quality of the different runs.\n",
    "    \n",
    "    Args:\n",
    "        trial (optuna.trial.Trial) Wrapper that controls the launching and the\n",
    "            hyper-parameters of the different runs.\n",
    "            \n",
    "    Returns:\n",
    "        (float) The quality metric of the current run.\n",
    "        \n",
    "    \"\"\"    \n",
    "    # Build model\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            filters=trial.suggest_categorical(\"filters\", [32, 64]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),\n",
    "            input_shape=INPUT_SHAPE,\n",
    "        )\n",
    "    )\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(CLASSES, activation=\"softmax\"))\n",
    "\n",
    "    # Compile model with sampled learning rate.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=RMSprop(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    # Run training\n",
    "    model.fit(x_train, y_train, shuffle=True, batch_size=BATCHSIZE, epochs=EPOCHS, verbose=False)\n",
    "\n",
    "    # Evaluate model quality (performance on validation set)\n",
    "    return model.evaluate(x_valid, y_valid, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Hyper-Parameter Optimisation\n",
    "\n",
    "In order to run the hyper-parameter optimisation we need to create a `study` object. It contains the main directives (and even the \"hyper-hyper-parameters\") of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Launch hyper-parameter search\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "\n",
    "# Show detailed info about finished trials\n",
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the optimisation metric for the different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = [trial.value for trial in study.trials]\n",
    "plt.plot(metrics, '.-'), plt.grid(True)\n",
    "plt.xlabel('trial'), plt.ylabel('metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the hyper-parameters for the best run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best trial\n",
    "trial = study.best_trial\n",
    "print('Best trial:', trial.number, '\\n')\n",
    "print('  Metric:', trial.value)\n",
    "print('  Params:')\n",
    "for key, value in trial.params.items():\n",
    "    print('\\t', key.ljust(13), ':', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show overall stats\n",
    "mu = np.mean([trial.value for trial in study.trials])\n",
    "std = np.std([trial.value for trial in study.trials])\n",
    "\n",
    "print('Avg metric:', np.mean(mu))\n",
    "print('Std metric:', np.mean(std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
