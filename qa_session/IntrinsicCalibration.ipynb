{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intrinsic Calibration\n",
    "\n",
    "In this notebook we will build a generic pipeline for camera [intrinsic calibration](https://www.analyticsvidhya.com/blog/2021/10/a-comprehensive-guide-for-camera-calibration-in-computer-vision/). We will be working with data that you can download from this public [repository](https://github.com/udacity/CarND-Advanced-Lane-Lines).\n",
    "\n",
    "The objective is to find the parameters of the camera optical system, i.e., its optical center, focal length and radial (or tangential) distortion coefficients of the lens.\n",
    "\n",
    "**Calibration Pipeline**\n",
    " - We will assume that the calibration target has not moved throughout the calibration (it might have moved but this does not affect the calibration). What is the position of the camera,relative to the reference target position, that has been used to take the pixture? -> rvecs, tvecs\n",
    " - We know the targets are flat and rectangular (all the corners are colinear). What are the distortion model parameters that would minimize the undistortion error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [20, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Calibration Images\n",
    "\n",
    "We start by taking images of the calibration pattern (typically a chessboard structure). Remember that camera calibration is an optimization process. We shall take multiple pictures and tray to cover the whole image area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "folder = 'camera_cal'\n",
    "fnames = os.listdir(folder)\n",
    "\n",
    "print('Num images', len(fnames))\n",
    "\n",
    "for idx, fname in enumerate(np.random.choice(fnames, 10)):\n",
    "    image = cv2.cvtColor(cv2.imread(os.path.join(folder, fname)), cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(2,5,idx+1), plt.imshow(image), plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calibration Parameters Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Target shape, i.e., the number of **inner** corners\n",
    "target_rows, target_cols = 6, 9\n",
    "\n",
    "# Optimization termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Prepare target reference 3D points, i.e., (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "pts_ref = np.zeros((target_rows * target_cols, 3), np.float32)\n",
    "pts_ref[:,:2] = np.mgrid[0:target_cols, 0:target_rows].T.reshape(-1, 2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "pts_tgt = [] # 3D point in real world space\n",
    "pts_img = [] # 2D points in image plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect Target Corners\n",
    "\n",
    "In this step, we are going to detect the inner corners of the calibration pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detections = []\n",
    "\n",
    "for fname in fnames:\n",
    "    image = cv2.imread(os.path.join(folder, fname))\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect target corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (target_cols, target_rows), None)\n",
    "    \n",
    "    # Refine the detected corners and add them to the calibration dataset\n",
    "    if ret == True:\n",
    "        # Target keypoints (always correspond to reference points)\n",
    "        pts_tgt.append(pts_ref)\n",
    "        \n",
    "        # Refine image points with subpixel precision and add them to dataset\n",
    "        corners = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)\n",
    "        pts_img.append(corners)\n",
    "        \n",
    "        # Draw and display the corners\n",
    "        detection = np.copy(image)\n",
    "        cv2.drawChessboardCorners(detection, (target_cols, target_rows), corners, ret)\n",
    "        detections.append(detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize random samples with the detected keypoints\n",
    "plt.rcParams['figure.figsize'] = [20, 12]\n",
    "for idx, detection in enumerate(np.random.choice(detections, 4)):\n",
    "    plt.subplot(2,2,idx+1), plt.imshow(detection), plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Camera Intrinsic Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Main calibration optimization process\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(pts_tgt, pts_img, gray.shape[::-1], None, None)\n",
    "\n",
    "# Undistort\n",
    "dst = cv2.undistort(gray, mtx, dist)\n",
    "\n",
    "\n",
    "plt.subplot(121), plt.imshow(gray, cmap='gray', vmin=0, vmax=255)\n",
    "plt.subplot(122), plt.imshow(dst, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = cv2.addWeighted(dst, 1.0, gray, 0.25, gamma=0)\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dst.shape, gray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Random Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(os.path.join(folder, np.random.choice(fnames)))\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "dst = cv2.undistort(gray, mtx, dist)\n",
    "\n",
    "result = cv2.addWeighted(dst, 1.0, gray, 0.25, gamma=0)\n",
    "plt.imshow(result, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
