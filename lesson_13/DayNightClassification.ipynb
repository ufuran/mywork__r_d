{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day-Night Image Classification\n",
    "\n",
    "In this notebook, we will implement a DNN classifier to classify images taken by stationary cameras as day or night images. We will also establish a baseline to make sure our deep learning implementation outperforms a simple hand-picked feature-based classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Loading\n",
    "\n",
    "We will use the day-night image dataset that you can download from [here](https://www.kaggle.com/datasets/stevemark/daynight-dataset?resource=download)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the different video sequences\n",
    "folder = '/media/janko/DATA/Datasets/day_night/archive/DNIM'\n",
    "sequences = [os.path.splitext(f)[0] for f in os.listdir(os.path.join(folder, 'time_stamp'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Visualization\n",
    "\n",
    "Let'sw now visualize some random data and the corresponding labels to see what we are dealing with here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = sequences[2]\n",
    "\n",
    "with open(os.path.join(folder, 'time_stamp', sequence + '.txt'), 'r') as fid:\n",
    "    data = fid.readlines()\n",
    "data = [d.strip() for d in data]\n",
    "\n",
    "fnames = [d.split(' ')[0] for d in data]\n",
    "hours = [int(d.split(' ')[-2]) for d in data]\n",
    "\n",
    "for cnt, idx in enumerate(np.random.randint(0, len(fnames), 6)):\n",
    "    image = cv2.imread(os.path.join(folder, 'Image', sequence, fnames[idx]))\n",
    "    plt.subplot(2, 3, cnt + 1), plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(hours[idx]), plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    "\n",
    "Now we will prepare the data for the training. That means that we load all the images, downsample them to a more treatable size and prepare the binary annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 64\n",
    "images, labels = [], []\n",
    "\n",
    "for sequence in tqdm(sequences):\n",
    "    # Read annotation file\n",
    "    with open(os.path.join(folder, 'time_stamp', sequence + '.txt'), 'r') as fid:\n",
    "        data = fid.readlines()\n",
    "\n",
    "    # Extract information\n",
    "    data = [d.strip() for d in data]\n",
    "    fnames = [d.split(' ')[0] for d in data]\n",
    "    hours = [int(d.split(' ')[-2]) for d in data]\n",
    "    \n",
    "    # Prepare training data\n",
    "    images = images + [cv2.cvtColor(cv2.resize(cv2.imread(os.path.join(folder, 'Image', sequence, f)),\n",
    "                                  (size, size)), cv2.COLOR_BGR2RGB) for f in fnames]    \n",
    "    labels = labels + hours\n",
    "    \n",
    "images = np.array(images)/255\n",
    "labels = np.array(labels)\n",
    "\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into day and night images\n",
    "labels = np.array([1 if (l <= 6 or l >= 18) else 0 for l in labels])\n",
    "\n",
    "# Are the two classes balanced?\n",
    "print('Num day images:  ', np.sum(labels == 0))\n",
    "print('Num night images:', np.sum(labels == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now shuffle the data and visualize them one last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images, labels = shuffle(images, labels)\n",
    "for cnt, idx in enumerate(np.random.randint(0, len(images), 6)):\n",
    "    plt.subplot(2, 3, cnt + 1), plt.imshow(images[idx], vmin=0, vmax=1), plt.title(labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Baseline\n",
    "\n",
    "Before we start training our neural network based model, we might need to establish a performance baseline. We do so to be able to tell whether the model is actually good or not.\n",
    "\n",
    "Since we are dealing with a day-night problem, the most straightforward approach is to use the mean color (or even luminance) to classify images as day vs night. So let's do it :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute mean color values for each image\n",
    "mu_day = [np.mean(i) for i, l in zip(images, labels) if l == 0]\n",
    "mu_night = [np.mean(i) for i, l in zip(images, labels) if l == 1]\n",
    "\n",
    "# Visualize the histograms of the obtained mean colors. Are they well separated?\n",
    "counts_day, bins_day = np.histogram(mu_day, bins=10)\n",
    "counts_night, bins_night = np.histogram(mu_night, bins=10)\n",
    "\n",
    "plt.bar(bins_day[0:-1], counts_day, width=0.025)\n",
    "plt.bar(bins_night[0:-1], counts_night, width=0.025)\n",
    "plt.legend(['Day', 'Night']), plt.xlabel('average color'), plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histograms do not seem that well separated. Anyway, let's find the optimal threshold that maximizes the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = []\n",
    "thresholds = np.arange(0.01, 1, 0.01)\n",
    "\n",
    "for th in thresholds:\n",
    "    acc.append((np.sum(mu_day >= th) + np.sum(mu_night < th)) / len(labels))\n",
    "    \n",
    "plt.plot(thresholds, acc, '.-'), plt.grid(True)\n",
    "plt.xlabel('threshold'), plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Classifier Based on Neural Networks\n",
    "\n",
    "Let's now build a NN-based classifier and let's see if we can beat the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(size, size, 3))\n",
    "\n",
    "net = Flatten()(inputs)\n",
    "net = Dense(16, activation='relu')(net)\n",
    "outputs = Dense(1, activation='sigmoid')(net)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compile the model and start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "batch_size = 128\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(images, labels, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = history.history\n",
    "epochs = range(len(h['loss']))\n",
    "\n",
    "plt.subplot(121), plt.plot(epochs, h['loss'], '.-'), plt.grid(True), plt.xlabel('epoch'), plt.title('loss')\n",
    "plt.subplot(122), plt.plot(epochs, h['accuracy'], '.-'), plt.grid(True), plt.xlabel('epoch'), plt.title('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = labels.flatten()\n",
    "y_pred = model.predict(images).flatten()\n",
    "\n",
    "y_pred_ = y_pred > 0.5\n",
    "\n",
    "# Overall accuracy\n",
    "num_samples = len(y_true)\n",
    "acc = np.sum(y_true == y_pred_)/num_samples\n",
    "\n",
    "# Accuracy for digit 0\n",
    "mask = y_true == 0\n",
    "acc0 = np.sum(y_true[mask] == y_pred_[mask])/np.sum(mask)\n",
    "\n",
    "# Accuracy for digit 1\n",
    "mask = y_true == 1\n",
    "acc1 = np.sum(y_true[mask] == y_pred_[mask])/np.sum(mask)\n",
    "\n",
    "print('Overall acc', acc)\n",
    "print('Digit-0 acc', acc0)\n",
    "print('Digit-1 acc', acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "for ii in range(15):\n",
    "    idx = np.random.randint(0, len(y_pred))\n",
    "    plt.subplot(3,5,ii+1), plt.imshow(images[idx, ...]), plt.axis(False)\n",
    "    plt.title('True: ' + str(y_true[idx]) + ' | Pred: ' + str(int(y_pred_[idx])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
