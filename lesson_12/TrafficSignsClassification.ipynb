{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Traffic Sign Classification\n",
    "\n",
    "This is our first notebook on neural networks. We will start by building a simple neural network that will help us to classify two types of traffic signs. The signs used in this lesson are a processed subset from the famous German Traffic Sign Recognition Database (GTSRB) that can be downloaded [here]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from time import time\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading\n",
    "\n",
    "Let's now load the data to see what we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/subset_lecture'\n",
    "\n",
    "# Load traffic sign class 0\n",
    "fnames_0 = os.listdir(os.path.join(folder, 'class_id_0'))\n",
    "images_0 = [cv2.imread(os.path.join(folder, 'class_id_0', f), cv2.IMREAD_UNCHANGED) for f in fnames_0]\n",
    "labels_0 = [0] * len(images_0)\n",
    "\n",
    "for cnt, idx in enumerate(np.random.randint(0, len(images_0), 10)):\n",
    "    plt.subplot(2,5,cnt+1)\n",
    "    plt.imshow(images_0[idx], cmap='gray', vmin=0, vmax=255)\n",
    "    plt.title(labels_0[idx]), plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load traffic sign class 1\n",
    "fnames_1 = os.listdir(os.path.join(folder, 'class_id_1'))\n",
    "images_1 = [cv2.imread(os.path.join(folder, 'class_id_1', f), cv2.IMREAD_UNCHANGED) for f in fnames_1]\n",
    "labels_1 = [1] * len(images_1)\n",
    "\n",
    "for cnt, idx in enumerate(np.random.randint(0, len(images_1), 10)):\n",
    "    plt.subplot(2,5,cnt+1)\n",
    "    plt.imshow(images_1[idx], cmap='gray', vmin=0, vmax=255)\n",
    "    plt.title(labels_1[idx]), plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Num samples class_0', len(images_0))\n",
    "print('Num samples class_1', len(images_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Input Data\n",
    "\n",
    "To train our neural network model, we have to prepare the data to the format the the model actually expects. In our case, this will be numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put both classes together and shuffle the data\n",
    "images = images_0 + images_1\n",
    "labels = labels_0 + labels_1\n",
    "images, labels = shuffle(images, labels)\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('Images', images.shape)\n",
    "print('Labels', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now we have a problem. We cannot just feed the image to a neuron since the neuron inputs are flat (one dimensional). On the other hand, the images are 2D matrices. Therefore, we need to \"flatten\" the images to a one dimensional vector of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "pixels = []\n",
    "for image in images:\n",
    "    pixels_ = []\n",
    "    for r in range(image.shape[0]):\n",
    "        for c in range(image.shape[1]):\n",
    "            pixels_.append(image[r,c])\n",
    "    pixels.append(pixels_)\n",
    "    \n",
    "pixels = np.array(pixels)/255\n",
    "stop = time()\n",
    "\n",
    "print('Shape', pixels.shape)\n",
    "print('Elapsed time', stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you know, just let make use of our friend numpy :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "pixels = np.array([image.flatten() for image in images])/255\n",
    "stop = time()\n",
    "\n",
    "print('Shape', pixels.shape)\n",
    "print('Elapsed time', stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the training, let's again have a look at some raqndom samples from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cnt, idx in enumerate(np.random.randint(0, len(images), 10)):    \n",
    "    plt.subplot(2,5,cnt+1)\n",
    "    plt.imshow(images[idx], cmap='gray', vmin=0, vmax=255)\n",
    "    plt.title(labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Neural Network\n",
    "\n",
    "Let's now build our first (and yes, very simple) neural network using Tensorflow. For that, we will need a couple of new imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following netowork will consist of only one single neuron. It is a very tiny network (not even a network, strictly speaking :-) ) and yet it can be quite powerful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(pixels.shape[1]))\n",
    "outputs = Dense(1, activation=\"linear\")(inputs)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file=\"model.png\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the training, we have to compile the model. During the compilation, we indicate what optimizer we want to use and what loss should be applied for the minimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer ='adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's train :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(pixels, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "h = history.history\n",
    "epochs = range(len(h['loss']))\n",
    "plt.plot(epochs, h['loss'], '.-'), plt.grid(True)\n",
    "plt.xlabel('epoch'), plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also have a looks at the learnt weights\n",
    "plt.plot(model.layers[1].weights[0].numpy(), '.-'), plt.grid(True)\n",
    "print(model.layers[1].weights[1].numpy(), model.layers[1].bias.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation\n",
    "\n",
    "Once our model is trained, we will can run it on our images to see how it performs (inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 50\n",
    "pred = model.predict(pixels[idx:idx+1, ...])\n",
    "print(pred, labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run it on the entire dataset\n",
    "predictions = model.predict(pixels).squeeze()\n",
    "predictions = predictions > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for prediction, label in zip(predictions, labels):\n",
    "    if prediction == label:\n",
    "        correct = correct + 1\n",
    "\n",
    "print('Accuracy', correct/len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnt, idx in enumerate(np.random.randint(0, len(images), 10)): \n",
    "    plt.subplot(2,5,cnt+1), plt.imshow(images[idx], cmap='gray', vmin=0, vmax=255)\n",
    "    plt.title('Label: ' + str(labels[idx]) + ' | Prediction: ' + str(predictions[idx]))\n",
    "    plt.axis(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
